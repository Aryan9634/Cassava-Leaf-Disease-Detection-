{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing requied modules","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\nimport torch\nimport torchvision \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\n\nimport cv2\nfrom PIL import Image\n\nimport os\nimport json\nimport random\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:43.591508Z","iopub.execute_input":"2023-05-10T10:44:43.592106Z","iopub.status.idle":"2023-05-10T10:44:49.486147Z","shell.execute_reply.started":"2023-05-10T10:44:43.592061Z","shell.execute_reply":"2023-05-10T10:44:49.484587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Setting up the enviornment ","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.489461Z","iopub.execute_input":"2023-05-10T10:44:49.489916Z","iopub.status.idle":"2023-05-10T10:44:49.498308Z","shell.execute_reply.started":"2023-05-10T10:44:49.489867Z","shell.execute_reply":"2023-05-10T10:44:49.496537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the distributed backend\n# os.environ['MASTER_ADDR'] = 'localhost'\n# os.environ['MASTER_PORT'] = '12345'\n# torch.distributed.init_process_group(backend='nccl', world_size=4)\n\n# For parallel TPUs,GPUs\nos.environ[\"XLA_USE_BF16\"] = \"1\"\nos.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.500832Z","iopub.execute_input":"2023-05-10T10:44:49.502749Z","iopub.status.idle":"2023-05-10T10:44:49.512466Z","shell.execute_reply.started":"2023-05-10T10:44:49.502697Z","shell.execute_reply":"2023-05-10T10:44:49.510795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These two lines of code are setting environment variables in the current Python session.\n\nThe first line sets the \"XLA_USE_BF16\" environment variable to the value \"1\". XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra operations that can be used to accelerate machine learning workloads on CPUs, GPUs, and TPUs. BF16 (bfloat16) is a floating-point format that uses 16 bits instead of the usual 32 bits used by the more common float32 format. By setting this environment variable to 1, you are telling XLA to use the BF16 format when possible, which can lead to faster performance on hardware that supports it.\n\nThe second line sets the \"XLA_TENSOR_ALLOCATOR_MAXSIZE\" environment variable to the value \"100000000\". This variable sets the maximum size, in bytes, that the XLA tensor allocator is allowed to allocate. The tensor allocator is responsible for managing the memory used by tensors (multidimensional arrays) in XLA computations. By increasing the maximum size, you are allowing XLA to allocate more memory, which can improve performance for larger models or datasets.\n\nOverall, these environment variables are used to configure the XLA runtime to potentially improve the performance of machine learning workloads in your Python session.","metadata":{}},{"cell_type":"markdown","source":"## Loading and reading data","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministicdet = True\n    torch.backends.cudnn.benchmark = False\nseed_everything(1001)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.516355Z","iopub.execute_input":"2023-05-10T10:44:49.520606Z","iopub.status.idle":"2023-05-10T10:44:49.531438Z","shell.execute_reply.started":"2023-05-10T10:44:49.520573Z","shell.execute_reply":"2023-05-10T10:44:49.530245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**os.environ[\"PYTHONHASHSEED\"] = str(seed)**\n\nThis line of code is setting an environment variable called \"PYTHONHASHSEED\" to the value of a variable named \"seed\", after converting it to a string using the str() function.\n\nIn Python, the built-in hash() function is used to generate hash values for objects like strings, tuples, and dictionaries. The hash value is used for various purposes, such as comparing objects for equality or storing them in a hash table.\n\nThe hash function in Python is based on the contents of the object being hashed and is therefore not deterministic across different runs of the program. This means that the hash value for an object can be different between different Python sessions, or even between different runs of the same program.\n\nBy setting the \"PYTHONHASHSEED\" environment variable to a fixed value, you are making the hash function deterministic within your Python session. This can be useful in certain situations, such as when you want to ensure that the same hash values are generated for the same objects across different runs of the program.\n\nThe value of \"seed\" can be any integer value. By setting it to a fixed value, you are ensuring that the hash function will always generate the same hash values for the same objects within your Python session.\n\n**torch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False**\n\nThese lines of code are setting the random seed for PyTorch operations, specifically for the CPU and GPU (CUDA) computations.\n\nThe first line sets the seed for the random number generator used by PyTorch on the CPU. The seed is an integer value that is used to initialize the random number generator, and by setting it to a fixed value, you are ensuring that the same sequence of random numbers is generated every time you run your program.\n\nThe second line sets the seed for the random number generator used by PyTorch on the GPU (CUDA). This is necessary if you are using CUDA to accelerate your computations, and you want to ensure that the same sequence of random numbers is generated every time you run your program.\n\nThe third line sets a flag in PyTorch's CUDA backend (cudnn) to ensure that the computations are deterministic. cudnn is a library that is used by PyTorch for fast convolutional operations on the GPU. By setting this flag to True, you are ensuring that the same results are generated every time you run your program.\n\nThe fourth line sets another flag in the cudnn backend to disable benchmarking. This is necessary when you want to ensure that the performance of your program is consistent across different runs. By default, cudnn will run a benchmark to determine the optimal configuration for the convolutional operations, but this can lead to inconsistencies in performance between different runs. By setting this flag to False, you are ensuring that the performance of your program is consistent, but you may sacrifice some performance gains that could be obtained from benchmarking.","metadata":{}},{"cell_type":"markdown","source":"## Setting Variables","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/cassava-leaf-disease-classification/\"\ntrain_images = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\"\ntest_images = \"/kaggle/input/cassava-leaf-disease-classification/test_images/\"\ntrain_labels = \"/kaggle/input/cassava-leaf-disease-classification/train.csv\"\nwith open(\"/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\",\"rb\") as f:\n    label_match = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.535193Z","iopub.execute_input":"2023-05-10T10:44:49.536895Z","iopub.status.idle":"2023-05-10T10:44:49.549703Z","shell.execute_reply.started":"2023-05-10T10:44:49.536853Z","shell.execute_reply":"2023-05-10T10:44:49.548316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(train_labels)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.552764Z","iopub.execute_input":"2023-05-10T10:44:49.553825Z","iopub.status.idle":"2023-05-10T10:44:49.604967Z","shell.execute_reply.started":"2023-05-10T10:44:49.553784Z","shell.execute_reply":"2023-05-10T10:44:49.603745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.609048Z","iopub.execute_input":"2023-05-10T10:44:49.609366Z","iopub.status.idle":"2023-05-10T10:44:49.639351Z","shell.execute_reply.started":"2023-05-10T10:44:49.609328Z","shell.execute_reply":"2023-05-10T10:44:49.637921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.label.value_counts().plot(kind=\"bar\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.642141Z","iopub.execute_input":"2023-05-10T10:44:49.643698Z","iopub.status.idle":"2023-05-10T10:44:49.878350Z","shell.execute_reply.started":"2023-05-10T10:44:49.643633Z","shell.execute_reply":"2023-05-10T10:44:49.877278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing the training images","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:55:08.567496Z","iopub.execute_input":"2023-04-24T10:55:08.568036Z","iopub.status.idle":"2023-04-24T10:55:08.575267Z","shell.execute_reply.started":"2023-04-24T10:55:08.567997Z","shell.execute_reply":"2023-04-24T10:55:08.573440Z"}}},{"cell_type":"code","source":"image_files = os.listdir(train_images[:-1])[:9]\nplt.figure(figsize=(10,5))\nfor i in range(len(image_files)):\n    plt.subplot(3,3,i+1)\n    image = cv2.imread(train_images+image_files[i])\n    plt.imshow(image)\n    a = df.iloc[i][\"label\"]\n    plt.title(f\"{a}:{label_match[str(a)]}\",fontdict={'fontsize':9})\n    plt.axis('off')\nplt.subplots_adjust(wspace=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:49.880844Z","iopub.execute_input":"2023-05-10T10:44:49.881221Z","iopub.status.idle":"2023-05-10T10:44:52.003127Z","shell.execute_reply.started":"2023-05-10T10:44:49.881181Z","shell.execute_reply":"2023-05-10T10:44:52.002121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data formatting ","metadata":{}},{"cell_type":"code","source":"#splitting data into training and validation\ntrain_df,val_df = train_test_split(df,test_size=0.1,random_state=42)\ntrain_df.shape,val_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.008436Z","iopub.execute_input":"2023-05-10T10:44:52.009195Z","iopub.status.idle":"2023-05-10T10:44:52.032052Z","shell.execute_reply.started":"2023-05-10T10:44:52.009155Z","shell.execute_reply":"2023-05-10T10:44:52.030963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preparing the dataset \nclass CassavaDataset(torch.utils.data.Dataset):\n    #Helper class to create pytorch dataset#\n    def __init__(self,df,data_path = data_path,mode=\"train\",transforms=None):\n        super().__init__()\n        self.df_data = df.values\n        self.data_path = data_path\n        self.transforms = transforms\n        self.mode = mode\n        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n    def __len__(self):\n        return len(self.df_data)\n    def __getitem__(self,index):\n        img_name,label = self.df_data[index]\n        img_path = os.path.join(self.data_path,self.data_dir,img_name)\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transforms is not None:\n            image = self.transforms(img)\n        return image,label","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.035714Z","iopub.execute_input":"2023-05-10T10:44:52.036597Z","iopub.status.idle":"2023-05-10T10:44:52.051635Z","shell.execute_reply.started":"2023-05-10T10:44:52.036556Z","shell.execute_reply":"2023-05-10T10:44:52.050296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation ","metadata":{}},{"cell_type":"code","source":"stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\ntrain_tfms = transforms.Compose([\n                 transforms.Resize((224, 224)),\n                 transforms.RandomHorizontalFlip(p=0.3),\n                 transforms.RandomVerticalFlip(p=0.3),\n                 transforms.RandomCrop(224, padding=4, padding_mode='reflect'), \n                 transforms.ToTensor(), \n                 transforms.Normalize(*stats,inplace=True),])\nvalid_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                         transforms.ToTensor(), \n                         transforms.Normalize(*stats)])","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.056814Z","iopub.execute_input":"2023-05-10T10:44:52.057361Z","iopub.status.idle":"2023-05-10T10:44:52.071424Z","shell.execute_reply.started":"2023-05-10T10:44:52.057315Z","shell.execute_reply":"2023-05-10T10:44:52.070315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Available Vision Transformer Models: \")\ntimm.list_models(\"vit*\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.076528Z","iopub.execute_input":"2023-05-10T10:44:52.079265Z","iopub.status.idle":"2023-05-10T10:44:52.097631Z","shell.execute_reply.started":"2023-05-10T10:44:52.079225Z","shell.execute_reply":"2023-05-10T10:44:52.096553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmented Data ","metadata":{}},{"cell_type":"code","source":"train_dataset = CassavaDataset(train_df, transforms=train_tfms)\nvalid_dataset = CassavaDataset(val_df, transforms=valid_tfms)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.102343Z","iopub.execute_input":"2023-05-10T10:44:52.104744Z","iopub.status.idle":"2023-05-10T10:44:52.114183Z","shell.execute_reply.started":"2023-05-10T10:44:52.104707Z","shell.execute_reply":"2023-05-10T10:44:52.112952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataLoader\ntrain_loader = DataLoader(train_dataset,100,shuffle=True,num_workers=2)\nval_loader = DataLoader(valid_dataset,100,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.119572Z","iopub.execute_input":"2023-05-10T10:44:52.122281Z","iopub.status.idle":"2023-05-10T10:44:52.129824Z","shell.execute_reply.started":"2023-05-10T10:44:52.122242Z","shell.execute_reply":"2023-05-10T10:44:52.128699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Classfication base","metadata":{}},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        return loss\n\n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def add_batch(self, x):\n        return x.unsqueeze(0)\n\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}],{} train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, \"last_lr: {:.5f},\".format(result['lrs'][-1]) if 'lrs' in result else '', \n            result['train_loss'], result['val_loss'], result['val_acc']))\n        \n    @torch.no_grad()\n    def evaluate(model, val_loader):\n        model.eval()\n        outputs = [model.validation_step(batch) for batch in val_loader]\n        return model.validation_epoch_end(outputs)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.133486Z","iopub.execute_input":"2023-05-10T10:44:52.135008Z","iopub.status.idle":"2023-05-10T10:44:52.157824Z","shell.execute_reply.started":"2023-05-10T10:44:52.134971Z","shell.execute_reply":"2023-05-10T10:44:52.156717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViT(ImageClassificationBase):\n    def __init__(self, num_classes, pretrained=True):\n        super().__init__()\n        self.network = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n        self.network.head = nn.Linear(self.network.head.in_features, num_classes)\n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.162902Z","iopub.execute_input":"2023-05-10T10:44:52.165902Z","iopub.status.idle":"2023-05-10T10:44:52.174696Z","shell.execute_reply.started":"2023-05-10T10:44:52.165864Z","shell.execute_reply":"2023-05-10T10:44:52.173641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    def __len__(self):\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.179544Z","iopub.execute_input":"2023-05-10T10:44:52.182497Z","iopub.status.idle":"2023-05-10T10:44:52.193960Z","shell.execute_reply.started":"2023-05-10T10:44:52.182460Z","shell.execute_reply":"2023-05-10T10:44:52.192881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(epochs, max_lr, model, train_loader, val_loader,\n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            optimizer.step()\n            optimizer.zero_grad()\n        result = model.evaluate(val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n                                                steps_per_epoch=len(train_loader))\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            optimizer.step()\n            optimizer.zero_grad()\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        result = model.evaluate(val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.199529Z","iopub.execute_input":"2023-05-10T10:44:52.202512Z","iopub.status.idle":"2023-05-10T10:44:52.223135Z","shell.execute_reply.started":"2023-05-10T10:44:52.202474Z","shell.execute_reply":"2023-05-10T10:44:52.222092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.228312Z","iopub.execute_input":"2023-05-10T10:44:52.231083Z","iopub.status.idle":"2023-05-10T10:44:52.304179Z","shell.execute_reply.started":"2023-05-10T10:44:52.230977Z","shell.execute_reply":"2023-05-10T10:44:52.303041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_loader, device)\nvalid_dl = DeviceDataLoader(val_loader, device)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.305721Z","iopub.execute_input":"2023-05-10T10:44:52.312157Z","iopub.status.idle":"2023-05-10T10:44:52.317649Z","shell.execute_reply.started":"2023-05-10T10:44:52.312117Z","shell.execute_reply":"2023-05-10T10:44:52.316377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finetuning the Pretrained Model","metadata":{}},{"cell_type":"code","source":"# model = ViT(df.label.nunique())\n# to_device(model, device)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.319179Z","iopub.execute_input":"2023-05-10T10:44:52.319792Z","iopub.status.idle":"2023-05-10T10:44:52.327419Z","shell.execute_reply.started":"2023-05-10T10:44:52.319748Z","shell.execute_reply":"2023-05-10T10:44:52.325957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = [model.evaluate(valid_dl)]\n# history","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.328949Z","iopub.execute_input":"2023-05-10T10:44:52.329488Z","iopub.status.idle":"2023-05-10T10:44:52.337979Z","shell.execute_reply.started":"2023-05-10T10:44:52.329448Z","shell.execute_reply":"2023-05-10T10:44:52.336854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.339009Z","iopub.execute_input":"2023-05-10T10:44:52.339454Z","iopub.status.idle":"2023-05-10T10:44:52.348577Z","shell.execute_reply.started":"2023-05-10T10:44:52.339417Z","shell.execute_reply":"2023-05-10T10:44:52.347441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,grad_clip=grad_clip, weight_decay=weight_decay, opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.349707Z","iopub.execute_input":"2023-05-10T10:44:52.350562Z","iopub.status.idle":"2023-05-10T10:44:52.358950Z","shell.execute_reply.started":"2023-05-10T10:44:52.350522Z","shell.execute_reply":"2023-05-10T10:44:52.357857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = ViT(df.label.nunique())\nto_device(model1, device)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:44:52.360019Z","iopub.execute_input":"2023-05-10T10:44:52.360448Z","iopub.status.idle":"2023-05-10T10:45:11.827932Z","shell.execute_reply.started":"2023-05-10T10:44:52.360405Z","shell.execute_reply":"2023-05-10T10:45:11.826713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(epochs, max_lr, model, train_loader, val_loader,\n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            optimizer.step()\n            optimizer.zero_grad()\n        result = model.evaluate(val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:45:11.829414Z","iopub.execute_input":"2023-05-10T10:45:11.830436Z","iopub.status.idle":"2023-05-10T10:45:11.842147Z","shell.execute_reply.started":"2023-05-10T10:45:11.830380Z","shell.execute_reply":"2023-05-10T10:45:11.839447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [model1.evaluate(valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:45:11.848002Z","iopub.execute_input":"2023-05-10T10:45:11.848288Z","iopub.status.idle":"2023-05-10T10:45:45.743420Z","shell.execute_reply.started":"2023-05-10T10:45:11.848260Z","shell.execute_reply":"2023-05-10T10:45:45.742098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history += fit(epochs, max_lr, model1, train_dl, valid_dl,grad_clip=grad_clip, weight_decay=weight_decay, opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:45:45.745415Z","iopub.execute_input":"2023-05-10T10:45:45.745823Z"},"trusted":true},"execution_count":null,"outputs":[]}]}